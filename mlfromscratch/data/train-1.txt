
Deep Feature-Based Text Clustering and its Explanation

*Keywords
Data Analysis, Data Mining, Learning Artificial Intelligence, Neural Nets, Pattern Clustering, Recurrent Neural Nets, Text Analysis, Bag Of Words Model, Classic Text Clustering Algorithms, Convolutional Neural Networks, Deep Feature Based Text Clustering Framework, Deep Learning Approach, Deep Learning Based Models, Existing Text Clustering Algorithms, Ignores Text, Lack Supervised Signals, Recurrent Neural Networks, Sequence Information, Sequence Representations, Sparsity Problems, State Of The Art Pretrained Language Model, Text Clustering Tasks, Text Data Analysis, Text Mining Community, Task Analysis, Computational Modeling, Feature Extraction, Clustering Algorithms, Semantics, Data Models, Recurrent Neural Networks, Deep Learning, Explanation Model, Feature Extraction, Text Clustering, Transfer Learning

*Abstract
Text clustering is a critical step in text data analysis and has been extensively studied by the text mining community. Most existing text clustering algorithms are based on the bag-of-words model, which faces the high-dimensional and sparsity problems and ignores text structural and sequence information. Deep learning-based models such as convolutional neural networks and recurrent neural networks regard texts as sequences but lack supervised signals and explainable results. In this paper, we propose a deep feature-based text clustering (DFTC) framework that incorporates pretrained text encoders into text clustering tasks. This model, which is based on sequence representations, breaks the dependency on supervision. The experimental results show that our model outperforms classic text clustering algorithms and the state-of-the-art pretrained language model BERT, on almost all the considered datasets. In addition, the explanation of the clustering results is significant for understanding the principles of the deep learning approach. Our proposed clustering framework includes an explanation module that can help users understand the meaning and quality of the clustering results.


[1] Self-organization massive document collection
[2] A survey of text clustering algorithms, in Mining Text Data
[3] A content-based recommender system for computer science publications, Knowledge-Based System.
[4] Text clustering with seeds affinity propagation
[5] Short text conceptualization using a probabilistic knowledge-base
[6] Latent Dirichlet allocation - generative model
[7] A Dirichlet multinomial mixture model-based approach for short text clustering
[8] Advances in natural language processing
[9] Hierarchical multi-label text classification: An attention-based recurrent network approach
[10] An analysis of the influence of deep neural network (DNN) topology in bottleneck feature based language recognition
[11] Neural machine translation by jointly learning to align and translate
[12] Self-Taught convolutional neural networks for short text clustering
[13] Semi-supervised clustering for short text via deep representation learning
[14] Ontology-based semantic similarity: A new feature-based approach
[15] Supervised learning of universal sentence representations from natural language inference data
[16] Deep contextualized word representations
[17] Efficient estimation of word representations in vector space
[18] A survey on transfer learning
[19] How transferable are features in deep neural networks
[20] Universal language model fine-tuning for text classification
[21] BERT: Pre-training of deep bidirectional transformers for language understanding
[22] Language models are unsupervised multitask learners
[23] Deep learning in neural networks: An overview
[24] Unsupervised deep embedding for clustering analysis
[25] Improved deep embedded clustering with local structure preservation
[26] Towards K-means-friendly spaces: Simultaneous deep learning and clustering
[27] Variational deep embedding: An unsupervised and generative approach to clustering
[28] RNNLM - Recurrent neural network language modeling toolkit
[29] LSTM - Long short-term memory
[30] Generating sequences with recurrent neural networks
[31] Regularizing and optimizing LSTM language models
[32] An analysis of neural language modeling at multiple scales
[33] Layer normalization
[34] Text understanding from scratch
[35] Locally consistent concept factorization for document clustering
[36] Document clustering based on non-negative matrix factorization
[37] Principal component analysis for clustering gene expression data
[38] Finding scientific topics
[39] Visualizing data using t-SNE
[40] The Inverted Pyramid: An Introduction to a Semiotics of Media Language

